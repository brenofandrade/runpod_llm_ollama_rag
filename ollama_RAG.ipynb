{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d0ae72",
   "metadata": {},
   "source": [
    "## Chat\n",
    "\n",
    "### Assistente de documentos \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cba9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b699fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think like humans and mimic their actions. The term may also be applied to any machine that exhibits traits associated with a human mind such as learning and problem-solving.\n",
       "\n",
       "At its core, AI involves the development of algorithms and statistical models that enable machines to perform tasks that typically require human intelligence, including:\n",
       "\n",
       "1. Visual perception\n",
       "2. Speech recognition\n",
       "3. Decision-making\n",
       "4. Language translation\n",
       "5. Expert systems\n",
       "\n",
       "There are several types of AI, including:\n",
       "\n",
       "1. **Narrow or Weak AI**: This type of AI is designed to perform a specific task, such as facial recognition or language translation.\n",
       "2. **General or Strong AI**: This type of AI would have the ability to understand, learn, and apply its intelligence to solve any problem, much like human intelligence.\n",
       "3. **Superintelligence**: This type of AI would have intelligence far beyond that of human beings, potentially leading to exponential growth in technological advancements.\n",
       "\n",
       "AI has many applications in various industries, including:\n",
       "\n",
       "1. **Virtual assistants**: Siri, Alexa, Google Assistant\n",
       "2. **Image and speech recognition**: Self-driving cars, facial recognition software\n",
       "3. **Healthcare**: Medical diagnosis, personalized medicine\n",
       "4. **Finance**: Algorithmic trading, risk analysis\n",
       "5. **Customer service**: Chatbots, virtual customer support\n",
       "\n",
       "The benefits of AI include:\n",
       "\n",
       "1. **Increased efficiency**: Automating repetitive tasks and improving productivity.\n",
       "2. **Improved accuracy**: Reducing errors in complex tasks like data analysis and decision-making.\n",
       "3. **Enhanced user experience**: Personalized recommendations, intelligent assistants, and more.\n",
       "\n",
       "However, AI also raises important questions about:\n",
       "\n",
       "1. **Job displacement**: Will AI replace human workers?\n",
       "2. **Bias and fairness**: Can AI systems be fair and unbiased?\n",
       "3. **Security and privacy**: How can we protect against AI-powered cyber threats?\n",
       "\n",
       "As AI continues to evolve and improve, it's essential to address these concerns and ensure that the benefits of AI are equitably distributed among all stakeholders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"llama3.2:latest\"\n",
    "\n",
    "llm = ChatOllama(model=model)\n",
    "response = llm.invoke(\"What is AI?\")\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2584f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "[-0.015132742, -0.0323724, 0.009370028, -0.038571354, -0.02837655]\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")\n",
    "vectorized_query = embeddings.embed_query(\"What is the meaning of Life?\")\n",
    "\n",
    "print(len(vectorized_query))\n",
    "print(vectorized_query[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c64377f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A question that has puzzled philosophers, theologians, scientists, and thinkers for centuries!\n",
       "\n",
       "There is no one definitive answer to the meaning of life, as it can vary greatly depending on individual perspectives, cultural backgrounds, and personal experiences. However, here are some possible interpretations:\n",
       "\n",
       "1. **Pursuit of happiness**: Many people believe that the meaning of life is to find happiness and fulfillment through various activities, relationships, and accomplishments.\n",
       "2. **Self-discovery**: Some see the meaning of life as a journey of self-discovery, where individuals explore their own values, passions, and purpose in life.\n",
       "3. **Love and connection**: Others argue that the meaning of life is rooted in our ability to form meaningful connections with others, build relationships, and experience love.\n",
       "4. **Personal growth**: Another perspective suggests that the meaning of life is to continuously learn, grow, and evolve as individuals, pushing beyond our limits and expanding our potential.\n",
       "5. **Leaving a legacy**: Some believe that the meaning of life is to make a positive impact on the world, leaving behind a lasting legacy that outlives us.\n",
       "6. **Spiritual or transcendent purpose**: Many people find meaning in their spiritual practices, faith, or connection with a higher power, which provides a sense of purpose and direction.\n",
       "7. **The present moment**: A more existentialist approach might argue that the meaning of life is found in the present moment, free from distractions and attachments to external goals or outcomes.\n",
       "8. **Contribution to society**: Some see the meaning of life as contributing to the greater good, making a positive difference in the lives of others, and leaving the world a better place than when we entered it.\n",
       "\n",
       "Ultimately, the meaning of life is a deeply personal and subjective question that each individual must answer for themselves. What do you think?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=model)\n",
    "\n",
    "response = llm.invoke(\"The meaning of life is\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1825ae",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a technique used to improve the performance and factual accuracy of Large Language Models (LLMs) by combining them with external knowledge retrieval.\n",
    "\n",
    "### ðŸ” What is RAG?\n",
    "RAG enhances LLMs by retrieving relevant information from external sources (like documents or databases) before generating a response. This helps the model answer questions or generate content based on up-to-date or domain-specific knowledge, rather than relying only on what it was trained on.\n",
    "\n",
    "---\n",
    "\n",
    "###  ðŸ§  How It Works (Simplified Pipeline)\n",
    "\n",
    "Query Understanding:\n",
    "\n",
    "> A user's input (question or prompt) is received.\n",
    "\n",
    "Retrieval Step:\n",
    "\n",
    "> The system searches a document store or knowledge base (often using vector similarity search) to find relevant context.\n",
    "\n",
    "Augmentation:\n",
    "\n",
    "> The retrieved information is combined with the original prompt.\n",
    "\n",
    "Generation:\n",
    "\n",
    "> The LLM uses this augmented input to generate a more accurate, informed, and grounded response.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### ðŸ§ª Example Use Case\n",
    "\n",
    "User prompt:\n",
    "\n",
    "\"What are the main takeaways from the latest Unimed annual report?\"\n",
    "\n",
    "Without RAG: The model might hallucinate or give general information.\n",
    "\n",
    "With RAG:\n",
    "\n",
    "Retrieve the most relevant pages from the uploaded PDF.\n",
    "\n",
    "Provide a summary grounded in real data.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… ** Benefits ** \n",
    "\n",
    "- Reduces hallucination\n",
    "\n",
    "- Adds up-to-date or private knowledge\n",
    "\n",
    "- Supports enterprise-specific applications\n",
    "\n",
    "âŒ ** Limitations ** \n",
    "\n",
    "- Retrieval quality affects generation\n",
    "\n",
    "- Requires careful setup of vector search\n",
    "\n",
    "- More complex architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ebc077",
   "metadata": {},
   "source": [
    "# ðŸ” RAG Pipeline Step-by-Step\n",
    "\n",
    "ðŸ“„ Document Load\n",
    "\n",
    "Load source documents (PDFs, text files, websites, etc.) into memory.\n",
    "\n",
    "Examples: PDFPlumber, PyMuPDF, BeautifulSoup, etc.\n",
    "\n",
    "âœ‚ï¸ Split\n",
    "\n",
    "Break documents into smaller, manageable chunks (passages, paragraphs).\n",
    "\n",
    "Tool: RecursiveCharacterTextSplitter (LangChain), or custom logic.\n",
    "\n",
    "ðŸ“¦ Vector Store (Embedding & Indexing)\n",
    "\n",
    "Convert each chunk into vector embeddings using a model (e.g., OpenAI, HuggingFace, Ollama, etc.).\n",
    "\n",
    "Store them in a Vector Database like FAISS, Chroma, Pinecone, or Weaviate.\n",
    "\n",
    "â“ Question (User Input)\n",
    "\n",
    "The user inputs a question or query through a chat or API interface.\n",
    "\n",
    "ðŸ” Query Semantic Search\n",
    "\n",
    "The user question is also embedded (into vector format) using the same embedding model.\n",
    "\n",
    "This vector is compared with those in the vector store to find the most similar chunks.\n",
    "\n",
    "ðŸ“š Retrieve Relevant Docs\n",
    "\n",
    "Based on similarity score, retrieve the top-k relevant document chunks.\n",
    "\n",
    "These serve as context for the LLM.\n",
    "\n",
    "ðŸ§  Prompt Construction\n",
    "\n",
    "Build a prompt that combines:\n",
    "\n",
    "The user question\n",
    "\n",
    "The retrieved context\n",
    "\n",
    "Optional: instructions, system prompt, format templates\n",
    "\n",
    "ðŸ¤– LLM (Large Language Model)\n",
    "\n",
    "The prompt is sent to the LLM (e.g., GPT-4o, Claude, Mistral, LLaMA).\n",
    "\n",
    "The LLM uses both the question and context to generate a response.\n",
    "\n",
    "ðŸ“ Output\n",
    "\n",
    "The model returns a generated text response.\n",
    "\n",
    "âœ… Answer\n",
    "\n",
    "Final output is returned to the user as the answer to their question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2373db",
   "metadata": {},
   "source": [
    "### Document Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6676c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c62d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"documents/eBook-How-to-Build-a-Career-in-AI.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "pages = []\n",
    "\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e915276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': 'documents/eBook-How-to-Build-a-Career-in-AI.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "PAGE 1\n",
      "Founder, DeepLearning.AI\n",
      "Collected Insights\n",
      "from Andrew Ng\n",
      "How to \n",
      "Build\n",
      "Your\n",
      "Career\n",
      "in AI\n",
      "A Simple Guide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{pages[0].metadata}\\n\")\n",
    "print(f\"{pages[0].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aee638cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGE 3\n",
      "Table of \n",
      "Contents\n",
      "Introduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Career Growth.\n",
      "Chapter 2: Learning Technical Skills for a \n",
      "Promising AI Career.\n",
      "Chapter 3: Should You Learn Math to Get a Job \n",
      "in AI?\n",
      "Chapter 4: Scoping Successful AI Projects.\n",
      "Chapter 5: Finding Projects that Complement \n",
      "Your Career Goals.\n",
      "Chapter 6: Building a Portfolio of Projects that \n",
      "Shows Skill Progression.\n",
      "Chapter 7: A Simple Framework for Starting Your AI \n",
      "Job Search.\n",
      "Chapter 8: Using Informational Interviews to Find \n",
      "the Right Job.\n",
      "Chapter 9: Finding the Right AI Job for You.\n",
      "Chapter 10: Keys to Building a Career in AI.\n",
      "Chapter 11: Overcoming Imposter Syndrome.\n",
      "Final Thoughts: Make Every Day Count.\n",
      "LEARNING\n",
      "PROJECTS\n",
      "JOB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{pages[2].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b6d56f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pages[2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0099720",
   "metadata": {},
   "source": [
    "### Split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f904a499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recursive Split\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 100\n",
    "chunk_overlap = 20\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents(pages[3].page_content)\n",
    "\n",
    "\n",
    "texts[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \" \",\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"\\u200b\",  # Zero-width space\n",
    "        \"\\uff0c\",  # Fullwidth comma\n",
    "        \"\\u3001\",  # Ideographic comma\n",
    "        \"\\uff0e\",  # Fullwidth full stop\n",
    "        \"\\u3002\",  # Ideographic full stop\n",
    "        \"\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2167c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715de96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9084ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198a9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87371ab9",
   "metadata": {},
   "source": [
    "### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7790fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocstore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01min_memory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryDocstore\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "import faiss \n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6a24b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(\n",
    "    len(\n",
    "        embeddings.embed_query(\"Hello world\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e36923f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00657393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c7a413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
